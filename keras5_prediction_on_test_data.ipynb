{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ayCwgJ0YPzHh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=2, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "Y6jA6aEfRYC7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Gdeb4t1lRaln"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from random import randint\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "-fkYIh9OV7YZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = []\n",
        "train_samples = []"
      ],
      "metadata": {
        "id": "hBEktWpXWFzE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(50):\n",
        "    # The ~5% of younger individuals who did experience side effects\n",
        "    random_younger = randint(13,64)\n",
        "    train_samples.append(random_younger)\n",
        "    train_labels.append(1)\n",
        "\n",
        "    # The ~5% of older individuals who did not experience side effects\n",
        "    random_older = randint(65,100)\n",
        "    train_samples.append(random_older)\n",
        "    train_labels.append(0)\n",
        "\n",
        "for i in range(1000):\n",
        "    # The ~95% of younger individuals who did not experience side effects\n",
        "    random_younger = randint(13,64)\n",
        "    train_samples.append(random_younger)\n",
        "    train_labels.append(0)\n",
        "\n",
        "    # The ~95% of older individuals who did experience side effects\n",
        "    random_older = randint(65,100)\n",
        "    train_samples.append(random_older)\n",
        "    train_labels.append(1)"
      ],
      "metadata": {
        "id": "S-YBRJ5DRkR1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = np.array(train_labels)\n",
        "train_samples = np.array(train_samples)\n",
        "train_labels, train_samples = shuffle(train_labels, train_samples)"
      ],
      "metadata": {
        "id": "ukNKP5v6RmuF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
      ],
      "metadata": {
        "id": "LgjyKC5ZRoBM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "      x=scaled_train_samples\n",
        "    , y=train_labels\n",
        "    , validation_split=0.1\n",
        "    , batch_size=10\n",
        "    , epochs=30\n",
        "    , verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKavwV3wSOaI",
        "outputId": "521a654b-b32c-40a7-a2b0-f904d94ceec5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "189/189 - 5s - loss: 0.6688 - accuracy: 0.5153 - val_loss: 0.6582 - val_accuracy: 0.5857 - 5s/epoch - 29ms/step\n",
            "Epoch 2/30\n",
            "189/189 - 1s - loss: 0.6439 - accuracy: 0.5852 - val_loss: 0.6344 - val_accuracy: 0.6571 - 563ms/epoch - 3ms/step\n",
            "Epoch 3/30\n",
            "189/189 - 1s - loss: 0.6180 - accuracy: 0.6550 - val_loss: 0.6075 - val_accuracy: 0.7000 - 502ms/epoch - 3ms/step\n",
            "Epoch 4/30\n",
            "189/189 - 1s - loss: 0.5847 - accuracy: 0.7164 - val_loss: 0.5710 - val_accuracy: 0.7238 - 552ms/epoch - 3ms/step\n",
            "Epoch 5/30\n",
            "189/189 - 0s - loss: 0.5449 - accuracy: 0.7857 - val_loss: 0.5328 - val_accuracy: 0.7667 - 331ms/epoch - 2ms/step\n",
            "Epoch 6/30\n",
            "189/189 - 0s - loss: 0.5039 - accuracy: 0.8339 - val_loss: 0.4967 - val_accuracy: 0.8143 - 295ms/epoch - 2ms/step\n",
            "Epoch 7/30\n",
            "189/189 - 0s - loss: 0.4688 - accuracy: 0.8619 - val_loss: 0.4658 - val_accuracy: 0.8143 - 345ms/epoch - 2ms/step\n",
            "Epoch 8/30\n",
            "189/189 - 0s - loss: 0.4368 - accuracy: 0.8709 - val_loss: 0.4375 - val_accuracy: 0.8381 - 339ms/epoch - 2ms/step\n",
            "Epoch 9/30\n",
            "189/189 - 0s - loss: 0.4083 - accuracy: 0.8889 - val_loss: 0.4128 - val_accuracy: 0.8476 - 347ms/epoch - 2ms/step\n",
            "Epoch 10/30\n",
            "189/189 - 0s - loss: 0.3832 - accuracy: 0.8942 - val_loss: 0.3917 - val_accuracy: 0.8619 - 290ms/epoch - 2ms/step\n",
            "Epoch 11/30\n",
            "189/189 - 1s - loss: 0.3617 - accuracy: 0.9042 - val_loss: 0.3733 - val_accuracy: 0.8762 - 547ms/epoch - 3ms/step\n",
            "Epoch 12/30\n",
            "189/189 - 0s - loss: 0.3432 - accuracy: 0.9143 - val_loss: 0.3583 - val_accuracy: 0.8857 - 480ms/epoch - 3ms/step\n",
            "Epoch 13/30\n",
            "189/189 - 0s - loss: 0.3277 - accuracy: 0.9169 - val_loss: 0.3459 - val_accuracy: 0.8857 - 497ms/epoch - 3ms/step\n",
            "Epoch 14/30\n",
            "189/189 - 0s - loss: 0.3147 - accuracy: 0.9185 - val_loss: 0.3355 - val_accuracy: 0.9095 - 493ms/epoch - 3ms/step\n",
            "Epoch 15/30\n",
            "189/189 - 1s - loss: 0.3040 - accuracy: 0.9275 - val_loss: 0.3269 - val_accuracy: 0.9095 - 503ms/epoch - 3ms/step\n",
            "Epoch 16/30\n",
            "189/189 - 0s - loss: 0.2951 - accuracy: 0.9280 - val_loss: 0.3200 - val_accuracy: 0.9095 - 372ms/epoch - 2ms/step\n",
            "Epoch 17/30\n",
            "189/189 - 0s - loss: 0.2877 - accuracy: 0.9291 - val_loss: 0.3144 - val_accuracy: 0.9238 - 335ms/epoch - 2ms/step\n",
            "Epoch 18/30\n",
            "189/189 - 0s - loss: 0.2814 - accuracy: 0.9302 - val_loss: 0.3100 - val_accuracy: 0.9238 - 342ms/epoch - 2ms/step\n",
            "Epoch 19/30\n",
            "189/189 - 0s - loss: 0.2764 - accuracy: 0.9296 - val_loss: 0.3059 - val_accuracy: 0.9238 - 294ms/epoch - 2ms/step\n",
            "Epoch 20/30\n",
            "189/189 - 0s - loss: 0.2722 - accuracy: 0.9328 - val_loss: 0.3029 - val_accuracy: 0.9238 - 306ms/epoch - 2ms/step\n",
            "Epoch 21/30\n",
            "189/189 - 0s - loss: 0.2684 - accuracy: 0.9302 - val_loss: 0.3004 - val_accuracy: 0.9238 - 383ms/epoch - 2ms/step\n",
            "Epoch 22/30\n",
            "189/189 - 0s - loss: 0.2652 - accuracy: 0.9302 - val_loss: 0.2982 - val_accuracy: 0.9238 - 301ms/epoch - 2ms/step\n",
            "Epoch 23/30\n",
            "189/189 - 0s - loss: 0.2624 - accuracy: 0.9312 - val_loss: 0.2962 - val_accuracy: 0.9238 - 332ms/epoch - 2ms/step\n",
            "Epoch 24/30\n",
            "189/189 - 0s - loss: 0.2600 - accuracy: 0.9323 - val_loss: 0.2947 - val_accuracy: 0.9238 - 316ms/epoch - 2ms/step\n",
            "Epoch 25/30\n",
            "189/189 - 0s - loss: 0.2580 - accuracy: 0.9317 - val_loss: 0.2928 - val_accuracy: 0.9286 - 324ms/epoch - 2ms/step\n",
            "Epoch 26/30\n",
            "189/189 - 0s - loss: 0.2560 - accuracy: 0.9323 - val_loss: 0.2914 - val_accuracy: 0.9286 - 299ms/epoch - 2ms/step\n",
            "Epoch 27/30\n",
            "189/189 - 0s - loss: 0.2543 - accuracy: 0.9323 - val_loss: 0.2901 - val_accuracy: 0.9286 - 342ms/epoch - 2ms/step\n",
            "Epoch 28/30\n",
            "189/189 - 0s - loss: 0.2528 - accuracy: 0.9360 - val_loss: 0.2892 - val_accuracy: 0.9286 - 285ms/epoch - 2ms/step\n",
            "Epoch 29/30\n",
            "189/189 - 0s - loss: 0.2515 - accuracy: 0.9328 - val_loss: 0.2880 - val_accuracy: 0.9286 - 346ms/epoch - 2ms/step\n",
            "Epoch 30/30\n",
            "189/189 - 0s - loss: 0.2502 - accuracy: 0.9349 - val_loss: 0.2872 - val_accuracy: 0.9286 - 315ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f64eb4d2740>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels =  []\n",
        "test_samples = []\n",
        "\n",
        "for i in range(10):\n",
        "    # The 5% of younger individuals who did experience side effects\n",
        "    random_younger = randint(13,64)\n",
        "    test_samples.append(random_younger)\n",
        "    test_labels.append(1)\n",
        "\n",
        "    # The 5% of older individuals who did not experience side effects\n",
        "    random_older = randint(65,100)\n",
        "    test_samples.append(random_older)\n",
        "    test_labels.append(0)\n",
        "\n",
        "for i in range(200):\n",
        "    # The 95% of younger individuals who did not experience side effects\n",
        "    random_younger = randint(13,64)\n",
        "    test_samples.append(random_younger)\n",
        "    test_labels.append(0)\n",
        "\n",
        "    # The 95% of older individuals who did experience side effects\n",
        "    random_older = randint(65,100)\n",
        "    test_samples.append(random_older)\n",
        "    test_labels.append(1)\n",
        "\n",
        "test_labels = np.array(test_labels)\n",
        "test_samples = np.array(test_samples)\n",
        "test_labels, test_samples = shuffle(test_labels, test_samples)\n",
        "\n",
        "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1,1))"
      ],
      "metadata": {
        "id": "Tkzud3DRWh-V"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluating a test set**"
      ],
      "metadata": {
        "id": "RdKspOJdWuos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(\n",
        "      x=scaled_test_samples\n",
        "    , batch_size=10\n",
        "    , verbose=0\n",
        ")  "
      ],
      "metadata": {
        "id": "YfORoINgWzoE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in predictions:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEHcEuJqW2ZV",
        "outputId": "ddc5a49d-2a74-4831-e343-55120a848965"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.02351115 0.9764888 ]\n",
            "[0.04286475 0.95713526]\n",
            "[0.05760807 0.94239193]\n",
            "[0.02946011 0.9705398 ]\n",
            "[0.885198   0.11480197]\n",
            "[0.07172781 0.92827225]\n",
            "[0.96855587 0.0314442 ]\n",
            "[0.13690236 0.86309755]\n",
            "[0.885198   0.11480197]\n",
            "[0.96127903 0.03872104]\n",
            "[0.09511989 0.90488005]\n",
            "[0.76486194 0.2351381 ]\n",
            "[0.17457177 0.8254282 ]\n",
            "[0.05352768 0.94647235]\n",
            "[0.01752904 0.982471  ]\n",
            "[0.17457177 0.8254282 ]\n",
            "[0.04972108 0.95027894]\n",
            "[0.6130826 0.3869174]\n",
            "[0.15480348 0.84519655]\n",
            "[0.9696998  0.03030024]\n",
            "[0.83355886 0.16644113]\n",
            "[0.95090127 0.04909864]\n",
            "[0.76486194 0.2351381 ]\n",
            "[0.03691716 0.96308273]\n",
            "[0.10665148 0.8933486 ]\n",
            "[0.9690854  0.03091451]\n",
            "[0.96961266 0.03038727]\n",
            "[0.96886486 0.03113504]\n",
            "[0.01886725 0.9811328 ]\n",
            "[0.7897417  0.21025833]\n",
            "[0.02731565 0.9726843 ]\n",
            "[0.9571065  0.04289352]\n",
            "[0.30272973 0.6972702 ]\n",
            "[0.05760807 0.94239193]\n",
            "[0.02731565 0.9726843 ]\n",
            "[0.5071865 0.4928135]\n",
            "[0.09511989 0.90488005]\n",
            "[0.02532323 0.97467667]\n",
            "[0.83355886 0.16644113]\n",
            "[0.01752904 0.9824709 ]\n",
            "[0.02532323 0.97467667]\n",
            "[0.9300623  0.06993762]\n",
            "[0.96961266 0.03038727]\n",
            "[0.04286475 0.95713526]\n",
            "[0.96749634 0.03250366]\n",
            "[0.96886486 0.03113504]\n",
            "[0.19627832 0.80372167]\n",
            "[0.04972108 0.95027894]\n",
            "[0.96935016 0.03064979]\n",
            "[0.01752904 0.9824709 ]\n",
            "[0.21996461 0.78003544]\n",
            "[0.19627832 0.80372167]\n",
            "[0.05352768 0.94647235]\n",
            "[0.6466019  0.35339817]\n",
            "[0.02532323 0.97467667]\n",
            "[0.83355886 0.16644113]\n",
            "[0.96961266 0.03038727]\n",
            "[0.4356229 0.564377 ]\n",
            "[0.04972108 0.95027894]\n",
            "[0.03176741 0.9682326 ]\n",
            "[0.03176741 0.9682326 ]\n",
            "[0.9660255  0.03397448]\n",
            "[0.8126339  0.18736619]\n",
            "[0.7380148 0.2619853]\n",
            "[0.959477   0.04052303]\n",
            "[0.96289206 0.03710786]\n",
            "[0.03176741 0.9682326 ]\n",
            "[0.9695254  0.03047453]\n",
            "[0.93693703 0.06306302]\n",
            "[0.9660255  0.03397448]\n",
            "[0.96987313 0.03012692]\n",
            "[0.03691716 0.96308273]\n",
            "[0.05760807 0.94239193]\n",
            "[0.5071865 0.4928135]\n",
            "[0.36664453 0.63335544]\n",
            "[0.85257083 0.14742906]\n",
            "[0.40064174 0.59935826]\n",
            "[0.19627832 0.80372167]\n",
            "[0.9660255  0.03397448]\n",
            "[0.93006235 0.06993762]\n",
            "[0.86975056 0.13024935]\n",
            "[0.5071865 0.4928135]\n",
            "[0.9300623  0.06993762]\n",
            "[0.03424904 0.9657509 ]\n",
            "[0.04286475 0.95713526]\n",
            "[0.07786932 0.92213064]\n",
            "[0.9693501  0.03064978]\n",
            "[0.96749634 0.03250366]\n",
            "[0.9700455  0.02995455]\n",
            "[0.9697865  0.03021345]\n",
            "[0.04286475 0.95713526]\n",
            "[0.57845694 0.42154312]\n",
            "[0.15480348 0.84519655]\n",
            "[0.969438   0.03056204]\n",
            "[0.78974175 0.21025835]\n",
            "[0.96686196 0.03313806]\n",
            "[0.07786932 0.92213064]\n",
            "[0.9695254  0.03047453]\n",
            "[0.17457177 0.8254282 ]\n",
            "[0.02946011 0.97053987]\n",
            "[0.9692621  0.03073779]\n",
            "[0.47125706 0.52874285]\n",
            "[0.06665839 0.93334156]\n",
            "[0.33392513 0.6660749 ]\n",
            "[0.9693501  0.03064978]\n",
            "[0.9701312  0.02986872]\n",
            "[0.15480348 0.84519655]\n",
            "[0.885198   0.11480197]\n",
            "[0.96917397 0.03082603]\n",
            "[0.0858799  0.91412014]\n",
            "[0.02030548 0.9796946 ]\n",
            "[0.10665148 0.8933486 ]\n",
            "[0.96886486 0.03113504]\n",
            "[0.5430419 0.4569581]\n",
            "[0.96788526 0.03211471]\n",
            "[0.961279   0.03872104]\n",
            "[0.91131157 0.08868846]\n",
            "[0.04617196 0.95382804]\n",
            "[0.02030548 0.97969455]\n",
            "[0.2732531  0.72674686]\n",
            "[0.85257083 0.14742906]\n",
            "[0.07786932 0.92213064]\n",
            "[0.03691716 0.96308273]\n",
            "[0.09511989 0.90488005]\n",
            "[0.06665839 0.93334156]\n",
            "[0.03176741 0.9682326 ]\n",
            "[0.01886725 0.9811328 ]\n",
            "[0.9692621  0.03073779]\n",
            "[0.70926744 0.29073256]\n",
            "[0.2732531  0.72674686]\n",
            "[0.8126339  0.18736619]\n",
            "[0.02030548 0.9796946 ]\n",
            "[0.17457177 0.8254282 ]\n",
            "[0.959477   0.04052303]\n",
            "[0.02185092 0.97814906]\n",
            "[0.21996461 0.78003544]\n",
            "[0.91131157 0.08868846]\n",
            "[0.9651687  0.03483126]\n",
            "[0.5430419 0.4569581]\n",
            "[0.4712571 0.5287429]\n",
            "[0.96855587 0.0314442 ]\n",
            "[0.10665148 0.8933486 ]\n",
            "[0.95090127 0.04909864]\n",
            "[0.10665148 0.8933486 ]\n",
            "[0.9697865  0.03021345]\n",
            "[0.01886725 0.9811328 ]\n",
            "[0.24563566 0.75436425]\n",
            "[0.07172781 0.92827225]\n",
            "[0.9678853  0.03211472]\n",
            "[0.96127903 0.03872104]\n",
            "[0.09511989 0.90488005]\n",
            "[0.01752904 0.982471  ]\n",
            "[0.5071865 0.4928135]\n",
            "[0.9695254  0.03047453]\n",
            "[0.04972108 0.95027894]\n",
            "[0.9701312  0.02986872]\n",
            "[0.21996461 0.78003544]\n",
            "[0.05760807 0.94239193]\n",
            "[0.30272976 0.6972703 ]\n",
            "[0.4712571 0.5287429]\n",
            "[0.936937   0.06306301]\n",
            "[0.9426325  0.05736755]\n",
            "[0.02532323 0.97467667]\n",
            "[0.96987313 0.03012692]\n",
            "[0.33392513 0.6660749 ]\n",
            "[0.0858799  0.91412014]\n",
            "[0.96788526 0.03211471]\n",
            "[0.959477   0.04052303]\n",
            "[0.43562296 0.56437707]\n",
            "[0.8697506  0.13024937]\n",
            "[0.02030548 0.9796946 ]\n",
            "[0.0858799  0.91412014]\n",
            "[0.01886725 0.9811328 ]\n",
            "[0.02185092 0.97814906]\n",
            "[0.03176741 0.9682326 ]\n",
            "[0.9682438  0.03175632]\n",
            "[0.24563566 0.75436425]\n",
            "[0.9651687  0.03483126]\n",
            "[0.2732531  0.72674686]\n",
            "[0.73801476 0.26198527]\n",
            "[0.21996461 0.78003544]\n",
            "[0.4356229 0.564377 ]\n",
            "[0.96429116 0.03570884]\n",
            "[0.6130826 0.3869174]\n",
            "[0.9701312  0.02986872]\n",
            "[0.5430419 0.4569581]\n",
            "[0.96855587 0.0314442 ]\n",
            "[0.17457177 0.8254282 ]\n",
            "[0.15480348 0.84519655]\n",
            "[0.70926744 0.29073256]\n",
            "[0.969438   0.03056204]\n",
            "[0.0858799  0.91412014]\n",
            "[0.9700454  0.02995455]\n",
            "[0.96855587 0.0314442 ]\n",
            "[0.13690236 0.86309755]\n",
            "[0.02946011 0.9705398 ]\n",
            "[0.12077556 0.87922436]\n",
            "[0.36664453 0.63335544]\n",
            "[0.3666445  0.63335544]\n",
            "[0.04972108 0.95027894]\n",
            "[0.01886725 0.9811328 ]\n",
            "[0.96686196 0.03313806]\n",
            "[0.9697865  0.03021345]\n",
            "[0.15480348 0.84519655]\n",
            "[0.83355886 0.16644113]\n",
            "[0.33392513 0.6660749 ]\n",
            "[0.9542262  0.04577375]\n",
            "[0.4356229 0.564377 ]\n",
            "[0.64660186 0.35339814]\n",
            "[0.05352768 0.94647235]\n",
            "[0.9699594  0.03004062]\n",
            "[0.30272973 0.6972702 ]\n",
            "[0.04286475 0.95713526]\n",
            "[0.2732531  0.72674686]\n",
            "[0.21996461 0.78003544]\n",
            "[0.02030548 0.9796946 ]\n",
            "[0.40064174 0.59935826]\n",
            "[0.04972108 0.95027894]\n",
            "[0.17457177 0.8254282 ]\n",
            "[0.76486194 0.2351381 ]\n",
            "[0.03176741 0.9682326 ]\n",
            "[0.03978455 0.9602154 ]\n",
            "[0.4356229 0.564377 ]\n",
            "[0.40064174 0.59935826]\n",
            "[0.17457177 0.8254282 ]\n",
            "[0.96788526 0.03211471]\n",
            "[0.24563566 0.75436425]\n",
            "[0.07172781 0.92827225]\n",
            "[0.2732531  0.72674686]\n",
            "[0.02185092 0.978149  ]\n",
            "[0.9692621  0.03073779]\n",
            "[0.6466019  0.35339817]\n",
            "[0.05760807 0.94239193]\n",
            "[0.10665148 0.8933486 ]\n",
            "[0.8990259  0.10097393]\n",
            "[0.03424904 0.9657509 ]\n",
            "[0.17457177 0.8254282 ]\n",
            "[0.05352768 0.94647235]\n",
            "[0.05760807 0.9423919 ]\n",
            "[0.9699593  0.03004062]\n",
            "[0.6130826 0.3869174]\n",
            "[0.07786932 0.92213064]\n",
            "[0.9660255  0.03397448]\n",
            "[0.04286475 0.95713526]\n",
            "[0.96749634 0.03250366]\n",
            "[0.05760807 0.94239193]\n",
            "[0.78974175 0.21025835]\n",
            "[0.9699594  0.03004062]\n",
            "[0.92143685 0.07856316]\n",
            "[0.885198   0.11480197]\n",
            "[0.9426325  0.05736755]\n",
            "[0.02946011 0.9705398 ]\n",
            "[0.03691716 0.96308273]\n",
            "[0.9695254  0.03047453]\n",
            "[0.9571065  0.04289352]\n",
            "[0.96886486 0.03113504]\n",
            "[0.01752904 0.982471  ]\n",
            "[0.78974175 0.21025835]\n",
            "[0.57845694 0.42154312]\n",
            "[0.2199646 0.7800354]\n",
            "[0.7380148 0.2619853]\n",
            "[0.96289206 0.03710786]\n",
            "[0.85257083 0.14742906]\n",
            "[0.40064174 0.59935826]\n",
            "[0.96686196 0.03313806]\n",
            "[0.06665839 0.93334156]\n",
            "[0.47125706 0.52874285]\n",
            "[0.9692621  0.03073779]\n",
            "[0.01886725 0.9811328 ]\n",
            "[0.04617196 0.9538281 ]\n",
            "[0.17457177 0.8254282 ]\n",
            "[0.96429116 0.03570884]\n",
            "[0.92143685 0.07856316]\n",
            "[0.03176741 0.9682326 ]\n",
            "[0.76486194 0.2351381 ]\n",
            "[0.09511989 0.90488005]\n",
            "[0.9651687  0.03483126]\n",
            "[0.96855587 0.0314442 ]\n",
            "[0.8697506  0.13024937]\n",
            "[0.03691716 0.9630828 ]\n",
            "[0.19627832 0.80372167]\n",
            "[0.8990259  0.10097393]\n",
            "[0.19627832 0.80372167]\n",
            "[0.33392513 0.6660749 ]\n",
            "[0.07172781 0.92827225]\n",
            "[0.02946011 0.9705398 ]\n",
            "[0.96886486 0.03113504]\n",
            "[0.961279   0.03872104]\n",
            "[0.02946011 0.97053987]\n",
            "[0.96935016 0.03064979]\n",
            "[0.96987313 0.03012692]\n",
            "[0.21996461 0.78003544]\n",
            "[0.03691716 0.96308273]\n",
            "[0.9691739  0.03082603]\n",
            "[0.6787388 0.3212612]\n",
            "[0.9700454  0.02995455]\n",
            "[0.96749634 0.03250366]\n",
            "[0.86975056 0.13024935]\n",
            "[0.83355886 0.16644113]\n",
            "[0.40064174 0.59935826]\n",
            "[0.06197915 0.93802094]\n",
            "[0.9701312  0.02986872]\n",
            "[0.78974175 0.21025835]\n",
            "[0.9542262  0.04577375]\n",
            "[0.07786932 0.92213064]\n",
            "[0.36664453 0.63335544]\n",
            "[0.6466019  0.35339817]\n",
            "[0.961279   0.03872104]\n",
            "[0.4712571 0.5287429]\n",
            "[0.12077557 0.8792244 ]\n",
            "[0.9701312  0.02986872]\n",
            "[0.02030548 0.9796946 ]\n",
            "[0.8990259  0.10097393]\n",
            "[0.10665148 0.8933486 ]\n",
            "[0.85257083 0.14742906]\n",
            "[0.02532323 0.97467667]\n",
            "[0.8990259  0.10097393]\n",
            "[0.02946011 0.9705398 ]\n",
            "[0.96855587 0.0314442 ]\n",
            "[0.3666445  0.63335544]\n",
            "[0.03176741 0.9682326 ]\n",
            "[0.10665148 0.8933486 ]\n",
            "[0.15480348 0.84519655]\n",
            "[0.9691739  0.03082603]\n",
            "[0.96886486 0.03113504]\n",
            "[0.9542262  0.04577375]\n",
            "[0.05352768 0.94647235]\n",
            "[0.12077556 0.87922436]\n",
            "[0.04617196 0.9538281 ]\n",
            "[0.40064174 0.59935826]\n",
            "[0.9690854  0.03091451]\n",
            "[0.02532323 0.97467667]\n",
            "[0.7380148 0.2619853]\n",
            "[0.83355886 0.16644113]\n",
            "[0.01886725 0.9811328 ]\n",
            "[0.02351115 0.9764888 ]\n",
            "[0.96788526 0.03211471]\n",
            "[0.07786932 0.92213064]\n",
            "[0.30272976 0.6972703 ]\n",
            "[0.8126339  0.18736619]\n",
            "[0.03691716 0.96308273]\n",
            "[0.12077556 0.87922436]\n",
            "[0.96788526 0.03211471]\n",
            "[0.9571065  0.04289352]\n",
            "[0.9542262  0.04577375]\n",
            "[0.959477   0.04052303]\n",
            "[0.21996461 0.78003544]\n",
            "[0.04286475 0.95713526]\n",
            "[0.73801476 0.26198527]\n",
            "[0.64660186 0.35339814]\n",
            "[0.9660255  0.03397448]\n",
            "[0.21996461 0.78003544]\n",
            "[0.09511989 0.90488005]\n",
            "[0.04286475 0.95713526]\n",
            "[0.85257083 0.14742906]\n",
            "[0.21996461 0.78003544]\n",
            "[0.6787388 0.3212612]\n",
            "[0.47125706 0.52874285]\n",
            "[0.01886725 0.9811328 ]\n",
            "[0.70926744 0.29073256]\n",
            "[0.21996461 0.78003544]\n",
            "[0.969438   0.03056204]\n",
            "[0.07172781 0.92827225]\n",
            "[0.40064174 0.59935826]\n",
            "[0.83355886 0.16644113]\n",
            "[0.06197915 0.93802094]\n",
            "[0.5071865 0.4928135]\n",
            "[0.9300623  0.06993762]\n",
            "[0.9668619  0.03313806]\n",
            "[0.17457177 0.8254282 ]\n",
            "[0.961279   0.03872104]\n",
            "[0.02185092 0.97814906]\n",
            "[0.03691716 0.96308273]\n",
            "[0.04972108 0.95027894]\n",
            "[0.02030548 0.9796946 ]\n",
            "[0.9300623  0.06993762]\n",
            "[0.9542262  0.04577375]\n",
            "[0.30272973 0.6972702 ]\n",
            "[0.03691716 0.9630828 ]\n",
            "[0.02185092 0.978149  ]\n",
            "[0.9690854  0.03091451]\n",
            "[0.8990259  0.10097393]\n",
            "[0.96987313 0.03012692]\n",
            "[0.09511989 0.90488005]\n",
            "[0.83355886 0.16644113]\n",
            "[0.57845694 0.42154312]\n",
            "[0.05760807 0.94239193]\n",
            "[0.07786932 0.92213064]\n",
            "[0.33392513 0.6660749 ]\n",
            "[0.02185092 0.978149  ]\n",
            "[0.85257083 0.14742906]\n",
            "[0.33392513 0.6660749 ]\n",
            "[0.5430419 0.4569581]\n",
            "[0.2732531  0.72674686]\n",
            "[0.96289206 0.03710786]\n",
            "[0.06665839 0.93334156]\n",
            "[0.33392513 0.6660749 ]\n",
            "[0.91131157 0.08868846]\n",
            "[0.8126339  0.18736619]\n",
            "[0.02532324 0.9746767 ]\n",
            "[0.47125706 0.52874285]\n",
            "[0.9700454  0.02995455]\n",
            "[0.6787388 0.3212612]\n",
            "[0.6130826 0.3869174]\n",
            "[0.85257083 0.14742906]\n",
            "[0.92143685 0.07856316]\n",
            "[0.9695254  0.03047453]\n",
            "[0.2732531  0.72674686]\n",
            "[0.01886725 0.9811328 ]\n",
            "[0.17457177 0.8254282 ]\n",
            "[0.30272973 0.6972702 ]\n",
            "[0.12077556 0.87922436]\n",
            "[0.96686196 0.03313806]\n",
            "[0.02030548 0.9796946 ]\n",
            "[0.9471046  0.05289543]\n",
            "[0.85257083 0.14742906]\n",
            "[0.02185092 0.97814906]\n",
            "[0.02946011 0.9705398 ]\n",
            "[0.96855587 0.0314442 ]\n",
            "[0.95710653 0.04289353]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rounded_predictions = np.argmax(predictions, axis=-1)"
      ],
      "metadata": {
        "id": "ddoDl-dsXC5G"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in rounded_predictions:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAFY-EVxXT5m",
        "outputId": "201f1034-5b51-4540-e0a8-f0150c2d725c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    }
  ]
}