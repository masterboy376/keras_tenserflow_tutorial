{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZG6bQ8EVN0ZU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=2, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "MR3iatdWOEHJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Y47pE5R_OIrd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from random import randint\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "lwVTg099Oc5v"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = []\n",
        "train_samples = []"
      ],
      "metadata": {
        "id": "htMAaKHqOiLv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(50):\n",
        "    # The ~5% of younger individuals who did experience side effects\n",
        "    random_younger = randint(13,64)\n",
        "    train_samples.append(random_younger)\n",
        "    train_labels.append(1)\n",
        "\n",
        "    # The ~5% of older individuals who did not experience side effects\n",
        "    random_older = randint(65,100)\n",
        "    train_samples.append(random_older)\n",
        "    train_labels.append(0)\n",
        "\n",
        "for i in range(1000):\n",
        "    # The ~95% of younger individuals who did not experience side effects\n",
        "    random_younger = randint(13,64)\n",
        "    train_samples.append(random_younger)\n",
        "    train_labels.append(0)\n",
        "\n",
        "    # The ~95% of older individuals who did experience side effects\n",
        "    random_older = randint(65,100)\n",
        "    train_samples.append(random_older)\n",
        "    train_labels.append(1)"
      ],
      "metadata": {
        "id": "VN1dnrSCOk4-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = np.array(train_labels)\n",
        "train_samples = np.array(train_samples)\n",
        "train_labels, train_samples = shuffle(train_labels, train_samples)"
      ],
      "metadata": {
        "id": "YhSY50eHOn1m"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
      ],
      "metadata": {
        "id": "DbnEzkkKOqNh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, verbose=2, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK8v8ICJORAb",
        "outputId": "d8d0182f-864b-4cae-bfba-9b60f7ae47b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "210/210 - 2s - loss: 0.6609 - accuracy: 0.5695 - 2s/epoch - 8ms/step\n",
            "Epoch 2/30\n",
            "210/210 - 1s - loss: 0.6303 - accuracy: 0.6448 - 535ms/epoch - 3ms/step\n",
            "Epoch 3/30\n",
            "210/210 - 0s - loss: 0.6016 - accuracy: 0.7000 - 488ms/epoch - 2ms/step\n",
            "Epoch 4/30\n",
            "210/210 - 0s - loss: 0.5665 - accuracy: 0.7514 - 465ms/epoch - 2ms/step\n",
            "Epoch 5/30\n",
            "210/210 - 0s - loss: 0.5301 - accuracy: 0.8090 - 375ms/epoch - 2ms/step\n",
            "Epoch 6/30\n",
            "210/210 - 0s - loss: 0.4963 - accuracy: 0.8405 - 309ms/epoch - 1ms/step\n",
            "Epoch 7/30\n",
            "210/210 - 0s - loss: 0.4639 - accuracy: 0.8495 - 290ms/epoch - 1ms/step\n",
            "Epoch 8/30\n",
            "210/210 - 0s - loss: 0.4322 - accuracy: 0.8705 - 304ms/epoch - 1ms/step\n",
            "Epoch 9/30\n",
            "210/210 - 0s - loss: 0.4029 - accuracy: 0.8910 - 293ms/epoch - 1ms/step\n",
            "Epoch 10/30\n",
            "210/210 - 0s - loss: 0.3781 - accuracy: 0.8957 - 306ms/epoch - 1ms/step\n",
            "Epoch 11/30\n",
            "210/210 - 0s - loss: 0.3568 - accuracy: 0.9048 - 305ms/epoch - 1ms/step\n",
            "Epoch 12/30\n",
            "210/210 - 0s - loss: 0.3375 - accuracy: 0.9086 - 291ms/epoch - 1ms/step\n",
            "Epoch 13/30\n",
            "210/210 - 0s - loss: 0.3200 - accuracy: 0.9176 - 313ms/epoch - 1ms/step\n",
            "Epoch 14/30\n",
            "210/210 - 0s - loss: 0.3078 - accuracy: 0.9162 - 298ms/epoch - 1ms/step\n",
            "Epoch 15/30\n",
            "210/210 - 0s - loss: 0.2980 - accuracy: 0.9214 - 302ms/epoch - 1ms/step\n",
            "Epoch 16/30\n",
            "210/210 - 0s - loss: 0.2901 - accuracy: 0.9224 - 339ms/epoch - 2ms/step\n",
            "Epoch 17/30\n",
            "210/210 - 0s - loss: 0.2836 - accuracy: 0.9248 - 316ms/epoch - 2ms/step\n",
            "Epoch 18/30\n",
            "210/210 - 0s - loss: 0.2783 - accuracy: 0.9257 - 310ms/epoch - 1ms/step\n",
            "Epoch 19/30\n",
            "210/210 - 0s - loss: 0.2737 - accuracy: 0.9305 - 313ms/epoch - 1ms/step\n",
            "Epoch 20/30\n",
            "210/210 - 0s - loss: 0.2701 - accuracy: 0.9286 - 289ms/epoch - 1ms/step\n",
            "Epoch 21/30\n",
            "210/210 - 0s - loss: 0.2667 - accuracy: 0.9271 - 309ms/epoch - 1ms/step\n",
            "Epoch 22/30\n",
            "210/210 - 0s - loss: 0.2639 - accuracy: 0.9310 - 306ms/epoch - 1ms/step\n",
            "Epoch 23/30\n",
            "210/210 - 0s - loss: 0.2616 - accuracy: 0.9329 - 306ms/epoch - 1ms/step\n",
            "Epoch 24/30\n",
            "210/210 - 0s - loss: 0.2593 - accuracy: 0.9329 - 317ms/epoch - 2ms/step\n",
            "Epoch 25/30\n",
            "210/210 - 0s - loss: 0.2575 - accuracy: 0.9376 - 298ms/epoch - 1ms/step\n",
            "Epoch 26/30\n",
            "210/210 - 0s - loss: 0.2561 - accuracy: 0.9305 - 294ms/epoch - 1ms/step\n",
            "Epoch 27/30\n",
            "210/210 - 0s - loss: 0.2546 - accuracy: 0.9367 - 302ms/epoch - 1ms/step\n",
            "Epoch 28/30\n",
            "210/210 - 0s - loss: 0.2533 - accuracy: 0.9333 - 303ms/epoch - 1ms/step\n",
            "Epoch 29/30\n",
            "210/210 - 0s - loss: 0.2523 - accuracy: 0.9329 - 308ms/epoch - 1ms/step\n",
            "Epoch 30/30\n",
            "210/210 - 0s - loss: 0.2512 - accuracy: 0.9381 - 304ms/epoch - 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f34148612a0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}